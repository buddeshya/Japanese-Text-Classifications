{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-18T08:09:36.544514Z","iopub.execute_input":"2022-07-18T08:09:36.545653Z","iopub.status.idle":"2022-07-18T08:09:36.591305Z","shell.execute_reply.started":"2022-07-18T08:09:36.545520Z","shell.execute_reply":"2022-07-18T08:09:36.590173Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nif(device.type == \"cuda\"):\n    device_name = \"gpu\"\nelse:\n    device_name = \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:09:41.059795Z","iopub.execute_input":"2022-07-18T08:09:41.060313Z","iopub.status.idle":"2022-07-18T08:09:43.166551Z","shell.execute_reply.started":"2022-07-18T08:09:41.060269Z","shell.execute_reply":"2022-07-18T08:09:43.165521Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = pd.read_pickle(\"/kaggle/input/japanesetext/data.pkl\")\nlabel = pd.read_pickle(\"/kaggle/input/japanesetext/label.pkl\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:09:46.892177Z","iopub.execute_input":"2022-07-18T08:09:46.893197Z","iopub.status.idle":"2022-07-18T08:09:46.916159Z","shell.execute_reply.started":"2022-07-18T08:09:46.893147Z","shell.execute_reply":"2022-07-18T08:09:46.915202Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(zip(data, label), columns=(\"text\", \"label\"))","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:09:49.083616Z","iopub.execute_input":"2022-07-18T08:09:49.084316Z","iopub.status.idle":"2022-07-18T08:09:49.094442Z","shell.execute_reply.started":"2022-07-18T08:09:49.084279Z","shell.execute_reply":"2022-07-18T08:09:49.093402Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install fugashi[unidic-lite]\n!pip install mecab-python3\n!pip install unidic-lite","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:09:51.382064Z","iopub.execute_input":"2022-07-18T08:09:51.382423Z","iopub.status.idle":"2022-07-18T08:10:44.619988Z","shell.execute_reply.started":"2022-07-18T08:09:51.382393Z","shell.execute_reply":"2022-07-18T08:10:44.618690Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/code/kaerunantoka/my-preprocessing-for-japanese-text-data\nimport MeCab\n\nclass MecabTokenizer:\n    def __init__(self):\n        self.wakati = MeCab.Tagger('-Owakati')\n        self.wakati.parse('')\n\n    def tokenize(self, line):\n        txt = self.wakati.parse(line)\n        txt = txt.split()\n        return txt\n    \n    def mecab_tokenizer(self, line):\n        node = self.wakati.parseToNode(line)\n        keywords = []\n        while node:\n            if node.feature.split(\",\")[0] == \"名詞\":\n                keywords.append(node.surface)\n            node = node.next\n        return keywords ","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:11:46.186614Z","iopub.execute_input":"2022-07-18T08:11:46.187742Z","iopub.status.idle":"2022-07-18T08:11:46.197180Z","shell.execute_reply.started":"2022-07-18T08:11:46.187691Z","shell.execute_reply":"2022-07-18T08:11:46.195789Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tok = MecabTokenizer()\ntok.mecab_tokenizer(\"kaggle days 楽しいイベントでしたね\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:11:48.555757Z","iopub.execute_input":"2022-07-18T08:11:48.556473Z","iopub.status.idle":"2022-07-18T08:11:48.565761Z","shell.execute_reply.started":"2022-07-18T08:11:48.556434Z","shell.execute_reply":"2022-07-18T08:11:48.564718Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"tok.tokenize(\"kaggle days 楽しいイベントでしたね\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:11:50.368424Z","iopub.execute_input":"2022-07-18T08:11:50.368817Z","iopub.status.idle":"2022-07-18T08:11:50.377100Z","shell.execute_reply.started":"2022-07-18T08:11:50.368784Z","shell.execute_reply":"2022-07-18T08:11:50.375811Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(df[\"text\"][0])\nprint(\"-----------------\")\nprint(tok.mecab_tokenizer(df[\"text\"][0]))\nprint(\"-----------------\")\nprint(tok.tokenize(df[\"text\"][0]))","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:11:52.268764Z","iopub.execute_input":"2022-07-18T08:11:52.269417Z","iopub.status.idle":"2022-07-18T08:11:52.286399Z","shell.execute_reply.started":"2022-07-18T08:11:52.269372Z","shell.execute_reply":"2022-07-18T08:11:52.285199Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\ntqdm.pandas()\nimport re\n\npuncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '\\n', '\\xa0', '\\t',\n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '\\u3000', '\\u202f',\n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n\n\nhtml_tags = ['<p>', '</p>', '<table>', '</table>', '<tr>', '</tr>', '<ul>', '<ol>', '<dl>', '</ul>', '</ol>',\n             '</dl>', '<li>', '<dd>', '<dt>', '</li>', '</dd>', '</dt>', '<h1>', '</h1>',\n             '<br>', '<br/>', '<strong>', '</strong>', '<span>', '</span>', '<blockquote>', '</blockquote>',\n             '<pre>', '</pre>', '<div>', '</div>', '<h2>', '</h2>', '<h3>', '</h3>', '<h4>', '</h4>', '<h5>', '</h5>',\n             '<h6>', '</h6>', '<blck>', '<pr>', '<code>', '<th>', '</th>', '<td>', '</td>', '<em>', '</em>']\n\nempty_expressions = ['&lt;', '&gt;', '&amp;', '&nbsp;', \n                     '&emsp;', '&ndash;', '&mdash;', '&ensp;'\n                     '&quot;', '&#39;']\n\nother = ['span', 'style', 'href', 'input']\n\n\ndef pre_preprocess(x):\n    return str(x).lower()\n\ndef rm_spaces(text):\n    spaces = ['\\u200b', '\\u200e', '\\u202a', '\\u2009', '\\u2028', '\\u202c', '\\ufeff', '\\uf0d8', '\\u2061', '\\u3000', '\\x10', '\\x7f', '\\x9d', '\\xad',\n              '\\x97', '\\x9c', '\\x8b', '\\x81', '\\x80', '\\x8c', '\\x85', '\\x92', '\\x88', '\\x8d', '\\x80', '\\x8e', '\\x9a', '\\x94', '\\xa0', \n              '\\x8f', '\\x82', '\\x8a', '\\x93', '\\x90', '\\x83', '\\x96', '\\x9b', '\\x9e', '\\x99', '\\x87', '\\x84', '\\x9f',\n             ]\n    for space in spaces:\n            text = text.replace(space, ' ')\n    return text\n\ndef remove_urls(x):\n    x = re.sub(r'(https?://[a-zA-Z0-9.-]*)', r'', x)\n\n    # original\n    x = re.sub(r'(quote=\\w+\\s?\\w+;?\\w+)', r'', x)\n    return x\n\ndef clean_html_tags(x, stop_words=[]):      \n    for r in html_tags:\n        x = x.replace(r, '')\n    for r in empty_expressions:\n        x = x.replace(r, ' ')\n    for r in stop_words:\n        x = x.replace(r, '')\n    return x\n\ndef replace_num(text):\n    text = re.sub('[0-9]{5,}', '', text)\n    text = re.sub('[0-9]{4}', '', text)\n    text = re.sub('[0-9]{3}', '', text)\n    text = re.sub('[0-9]{2}', '', text)\n    return text\n\ndef get_url_num(x):\n    pattern = \"https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+\"\n    urls = re.findall(pattern, x)\n    return len(urls)\n\n\ndef clean_puncts(x):\n    for punct in puncts:\n        x = x.replace(punct, f' {punct} ')\n    return x\n\n#zenkaku = '０,１,２,３,４,５,６,７,８,９,（,）,＊,「,」,［,］,【,】,＜,＞,？,・,＃,＠,＄,％,＝'.split(',')\n#hankaku = '0,1,2,3,4,5,6,7,8,9,q,a,z,w,s,x,c,d,e,r,f,v,b,g,t,y,h,n,m,j,u,i,k,l,o,p'.split(',')\n\ndef clean_text_jp(x):\n    x = x.replace('。', '')\n    x = x.replace('、', '')\n    x = x.replace('\\n', '') # 改行削除\n    x = x.replace('\\t', '') # タブ削除\n    x = x.replace('\\r', '')\n    x = re.sub(re.compile(r'[!-\\/:-@[-`{-~]'), ' ', x) \n    x = re.sub(r'\\[math\\]', ' LaTex math ', x) # LaTex削除\n    x = re.sub(r'\\[\\/math\\]', ' LaTex math ', x) # LaTex削除\n    x = re.sub(r'\\\\', ' LaTex ', x) # LaTex削除   \n    #for r in zenkaku+hankaku:\n    #    x = x.replace(str(r), '')\n    x = re.sub(' +', ' ', x)\n    return x\n\n\ndef preprocess(data):\n    data = data.progress_apply(lambda x: pre_preprocess(x))\n    data = data.progress_apply(lambda x: rm_spaces(x))\n    data = data.progress_apply(lambda x: remove_urls(x))\n    data = data.progress_apply(lambda x: clean_puncts(x))\n    data = data.progress_apply(lambda x: replace_num(x))\n    data = data.progress_apply(lambda x: clean_html_tags(x, stop_words=other))\n    data = data.progress_apply(lambda x: clean_text_jp(x))\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:11:55.354597Z","iopub.execute_input":"2022-07-18T08:11:55.355103Z","iopub.status.idle":"2022-07-18T08:11:55.388792Z","shell.execute_reply.started":"2022-07-18T08:11:55.355047Z","shell.execute_reply":"2022-07-18T08:11:55.387726Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df['text'] = preprocess(df['text'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:12:00.662274Z","iopub.execute_input":"2022-07-18T08:12:00.663195Z","iopub.status.idle":"2022-07-18T08:12:01.108808Z","shell.execute_reply.started":"2022-07-18T08:12:00.663157Z","shell.execute_reply":"2022-07-18T08:12:01.107603Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df['mecab_tokenizer'] = df['text'].progress_apply(lambda x: ' '.join(tok.mecab_tokenizer(x)))\n# df['tokenize'] = df['text'].progress_apply(lambda x: ' '.join(tok.tokenize(x)))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:12:04.202535Z","iopub.execute_input":"2022-07-18T08:12:04.203243Z","iopub.status.idle":"2022-07-18T08:12:04.495293Z","shell.execute_reply.started":"2022-07-18T08:12:04.203201Z","shell.execute_reply":"2022-07-18T08:12:04.494282Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import gensim\nurl = \"/kaggle/input/japanese-vector/entity_vector.model.bin\"\nembeddings = gensim.models.KeyedVectors.load_word2vec_format(url, binary=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:12:07.516341Z","iopub.execute_input":"2022-07-18T08:12:07.516958Z","iopub.status.idle":"2022-07-18T08:12:29.587567Z","shell.execute_reply.started":"2022-07-18T08:12:07.516918Z","shell.execute_reply":"2022-07-18T08:12:29.586493Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\ntok = Tokenizer()\ntok.fit_on_texts(df['mecab_tokenizer'])\nvocab_size = len(tok.word_index) + 1\nencd_rev = tok.texts_to_sequences(df['mecab_tokenizer'])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:12:51.321957Z","iopub.execute_input":"2022-07-18T08:12:51.322942Z","iopub.status.idle":"2022-07-18T08:12:57.472802Z","shell.execute_reply.started":"2022-07-18T08:12:51.322901Z","shell.execute_reply":"2022-07-18T08:12:57.471725Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"vocab_size","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:12:57.474948Z","iopub.execute_input":"2022-07-18T08:12:57.475320Z","iopub.status.idle":"2022-07-18T08:12:57.484924Z","shell.execute_reply.started":"2022-07-18T08:12:57.475281Z","shell.execute_reply":"2022-07-18T08:12:57.483752Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"max_rev_len=40\nvocab_size = len(tok.word_index) + 1\nembed_dim=200","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:12:57.486726Z","iopub.execute_input":"2022-07-18T08:12:57.487331Z","iopub.status.idle":"2022-07-18T08:12:57.494022Z","shell.execute_reply.started":"2022-07-18T08:12:57.487290Z","shell.execute_reply":"2022-07-18T08:12:57.492696Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"pad_rev= pad_sequences(encd_rev, maxlen=max_rev_len, padding='post')\npad_rev.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:12:57.497618Z","iopub.execute_input":"2022-07-18T08:12:57.498342Z","iopub.status.idle":"2022-07-18T08:12:57.523124Z","shell.execute_reply.started":"2022-07-18T08:12:57.498302Z","shell.execute_reply":"2022-07-18T08:12:57.522283Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"embed_matrix=np.zeros(shape=(vocab_size,embed_dim))\nfor word,i in tok.word_index.items():\n    try:\n        embed_vector = embeddings[word] \n    except:\n        pass\n    if embed_vector is not None:\n            embed_matrix[i]=embed_vector","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:13:06.050327Z","iopub.execute_input":"2022-07-18T08:13:06.050743Z","iopub.status.idle":"2022-07-18T08:13:06.088101Z","shell.execute_reply.started":"2022-07-18T08:13:06.050705Z","shell.execute_reply":"2022-07-18T08:13:06.087043Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"embed_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:13:08.451401Z","iopub.execute_input":"2022-07-18T08:13:08.452153Z","iopub.status.idle":"2022-07-18T08:13:08.459052Z","shell.execute_reply.started":"2022-07-18T08:13:08.452111Z","shell.execute_reply":"2022-07-18T08:13:08.457877Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Y Axis df[\"label\"]\n#X axis pad_rev","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_X, test_X, train_y, test_y = train_test_split(pad_rev, df.label.values, test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:13:13.644413Z","iopub.execute_input":"2022-07-18T08:13:13.644831Z","iopub.status.idle":"2022-07-18T08:13:13.857189Z","shell.execute_reply.started":"2022-07-18T08:13:13.644785Z","shell.execute_reply":"2022-07-18T08:13:13.856169Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(\"Train shape : \",train_X.shape)\nprint(\"Test shape : \",test_X.shape)\nprint(\"Train shape : \",train_y.shape)\nprint(\"Test shape : \",test_y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:13:17.382454Z","iopub.execute_input":"2022-07-18T08:13:17.385450Z","iopub.status.idle":"2022-07-18T08:13:17.392560Z","shell.execute_reply.started":"2022-07-18T08:13:17.385410Z","shell.execute_reply":"2022-07-18T08:13:17.391357Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nbatch_size = 64\n\n\nx_train = torch.tensor(train_X, dtype=torch.long)\ny_train = torch.tensor(train_y, dtype=torch.long)\nx_cv = torch.tensor(test_X, dtype=torch.long)\ny_cv = torch.tensor(test_y, dtype=torch.long)\n\n\n# Create Torch datasets\ntrain = TensorDataset(x_train, y_train)\nvalid = TensorDataset(x_cv, y_cv)\n\n# Create Data Loaders\ntrain_loader = DataLoader(train, batch_size=batch_size, num_workers = os.cpu_count(), shuffle=True)\nvalid_loader = DataLoader(valid, batch_size=batch_size, num_workers = os.cpu_count(), shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:13:21.541508Z","iopub.execute_input":"2022-07-18T08:13:21.542274Z","iopub.status.idle":"2022-07-18T08:13:21.552563Z","shell.execute_reply.started":"2022-07-18T08:13:21.542231Z","shell.execute_reply":"2022-07-18T08:13:21.551156Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"for X, Y in train_loader:\n    print(X.shape, Y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:13:23.998198Z","iopub.execute_input":"2022-07-18T08:13:23.998714Z","iopub.status.idle":"2022-07-18T08:13:24.145588Z","shell.execute_reply.started":"2022-07-18T08:13:23.998653Z","shell.execute_reply":"2022-07-18T08:13:24.144304Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport os\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:13:30.509399Z","iopub.execute_input":"2022-07-18T08:13:30.510314Z","iopub.status.idle":"2022-07-18T08:13:33.071145Z","shell.execute_reply.started":"2022-07-18T08:13:30.510260Z","shell.execute_reply":"2022-07-18T08:13:33.069982Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from torch import nn, Tensor\nclass PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        pe = torch.zeros(max_len, 1, d_model)\n        pe[:, 0, 0::2] = torch.sin(position * div_term)\n        pe[:, 0, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x: Tensor) -> Tensor:\n        \"\"\"\n        Args:\n            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n        \"\"\"\n        self.pe = self.pe.squeeze()\n        x = x + self.pe[:x.size(0)]\n        return self.dropout(x)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:13:51.014791Z","iopub.execute_input":"2022-07-18T08:13:51.015951Z","iopub.status.idle":"2022-07-18T08:13:51.027198Z","shell.execute_reply.started":"2022-07-18T08:13:51.015910Z","shell.execute_reply":"2022-07-18T08:13:51.026028Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"position = torch.arange(40).unsqueeze(1)\ndiv_term= torch.exp(torch.arange(0, 200, 2) * (-math.log(10000.0) / 200))\npe = torch.zeros(40, 1, 200)\npe[:, 0, 0::2] = torch.sin(position * div_term)\npe[:, 0, 1::2] = torch.cos(position * div_term)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pe.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerDecoder(nn.Module):\n    def __init__(self, seq_len, embedding_dimension, n_cat):\n        super(TransformerDecoder, self).__init__()\n        self.decoder = nn.Linear(seq_len * embedding_dimension, n_cat)\n        \n    def forward(self, x):\n        x = torch.flatten(x, start_dim=1)\n        x = self.decoder(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:14:13.885330Z","iopub.execute_input":"2022-07-18T08:14:13.886501Z","iopub.status.idle":"2022-07-18T08:14:13.894421Z","shell.execute_reply.started":"2022-07-18T08:14:13.886460Z","shell.execute_reply":"2022-07-18T08:14:13.893386Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"weight = torch.FloatTensor(embed_matrix)\n\nclass TransformerNET(pl.LightningModule):\n    def __init__(self,\n                 vocab_size,\n                 nhead,\n                 seq_len,\n                 n_cat,\n                 embedding_dimension=200,\n                 n_layers = 2,\n                 dropout=0.1\n                ):\n        super().__init__()\n        \n        self.embedding_dimension = embedding_dimension\n        \n        self.encoder = nn.Embedding.from_pretrained(weight)\n        self.encoder.weight.requires_grad = True\n        \n        self.pos_encoder = PositionalEncoding(max_len = seq_len, d_model = embedding_dimension)\n        \n        encoder_layers = nn.TransformerEncoderLayer(embedding_dimension, nhead)\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, n_layers)\n        self.decoder = TransformerDecoder(seq_len, embedding_dimension, n_cat)\n        self.relu = nn.ReLU()\n        self.ce = nn.CrossEntropyLoss()\n        \n    def accuracy(self,pred, y):\n        pred = torch.argmax(pred, 1)\n        correct_pred = (pred == y).float()\n        acc = correct_pred.sum() / len(correct_pred)\n        return acc\n    \n    def _generate_square_subsequent_mask(self, sz):\n        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n\n    def forward(self, x):\n        inputs = x\n        mask = self._generate_square_subsequent_mask(len(x)).to(device)\n        x = self.encoder(x) * math.sqrt(self.embedding_dimension)\n        x = self.pos_encoder(x)\n        x = self.transformer_encoder(x, mask)\n        x = self.decoder(x)\n        return x\n    \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y = y.squeeze()\n        x = x.view(x.size(0), -1)\n        y_hat = self(x)\n        loss = self.ce(y_hat, y)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y= batch\n        y = y.squeeze()\n        x = x.view(x.size(0), -1)\n        y_hat = self(x)\n        loss = self.ce(y_hat, y)\n        self.log(\"val_loss\", loss)\n        return loss\n            \n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        y = y.squeeze()\n        x = x.view(x.size(0), -1)\n        y_hat = self(x)\n        accuracy = self.accuracy(y_hat, y)\n        #result = pl.EvalResult(checkpoint_on=accuracy)\n        self.log('test_accuracy', accuracy)\n        #print(accuracy)\n        return {\"test_accuracy\", accuracy} \n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:14:19.597187Z","iopub.execute_input":"2022-07-18T08:14:19.597574Z","iopub.status.idle":"2022-07-18T08:14:19.624076Z","shell.execute_reply.started":"2022-07-18T08:14:19.597540Z","shell.execute_reply":"2022-07-18T08:14:19.622953Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"print(vocab_size)\nmax_seq_len = 40\nNum_Catagories = 26\nmodel = TransformerNET(vocab_size = vocab_size, nhead = 2, seq_len = max_seq_len, n_cat = Num_Catagories)\ntrainer = pl.Trainer(callbacks=[EarlyStopping(monitor='val_loss', mode='min', patience= 30)], max_epochs = -1, accelerator= device_name, devices= 1)\ntrainer.fit(model, train_loader, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:32:17.838111Z","iopub.execute_input":"2022-07-18T08:32:17.838848Z","iopub.status.idle":"2022-07-18T08:33:09.847781Z","shell.execute_reply.started":"2022-07-18T08:32:17.838809Z","shell.execute_reply":"2022-07-18T08:33:09.846548Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"print(model.eval())\ntrainer.test(model, valid_loader)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T08:43:36.582858Z","iopub.execute_input":"2022-07-18T08:43:36.583278Z","iopub.status.idle":"2022-07-18T08:43:36.987798Z","shell.execute_reply.started":"2022-07-18T08:43:36.583243Z","shell.execute_reply":"2022-07-18T08:43:36.986743Z"},"trusted":true},"execution_count":34,"outputs":[]}]}